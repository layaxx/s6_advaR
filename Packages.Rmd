---
title: 'Random Forest vs. Gradient Boosting'
author: "Jonathan Loew, Yannick Lang"
date: 
output:
  prettydoc::html_pretty:
    theme: cayman
    highlight: github
    math: katex
    number_sections: yes
    toc: yes
    toc_depth: 2
    fig_caption: yes
    fig_width: 7
    fig_height: 7
    keep_md: yes
subtitle: 'verschiedene Random Forest / Gradient Boosting packages in R'
---

```{r setup, include=FALSE, purl=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Dataset
```{r}
library(pacman)

set.seed(42)

data <- MASS::Boston # data set to be used
row <- 14 # row of the data set that will be predicted

test_ids <- sample(nrow(data), 10)

training_data <- data[-test_ids, ]
training_data_x <- data[-test_ids, -row]
training_data_y <- data[-test_ids, row]

test_data_x <- data[test_ids, -row]
test_data_y <- data[test_ids, row]

formula <- formula(paste(names(data)[row], "~ ."))
```

# Benchmark
Die Benchmark function erwartet els Eingabe eine Funktion, die das Model generiert, eine optionale Zahl, die der Anzahl der Wiederholungen enspricht und einen Optionalen Titel f체r das generierte Diagram.
Zur체ckgegeben werden Standardabweichung/Durchschnitt der Differenz zwischen echten Werten des Testdatensatzes und den gesch채tzten Werten des (letzten) Models und die durchschnittliche Laufzeit der Modelgenerierung. Ausserdem werden die echten Werten des Testdatensatzes und den gesch채tzten Werten des (letzten) Models geplottet.
```{r}
benchmark <- function(createModel, times = 1, title = "Benchmark") {
  start_time <- Sys.time()
  for (idx in 1:times) {
    model <- createModel()
  }
  end_time <- Sys.time()

  predicted_values <- predict(model, test_data_x)

  plot(1:length(test_data_y),
    test_data_y,
    col = "black",
    main = title,
    xlab = "data points", ylab = "y values"
  )
  points(1:length(test_data_y), predicted_values, col = "purple")
  legend(
    "topright",
    legend = c("Actual values", "Predicted values"),
    pch = 1,
    col = c("black", "purple")
  )


  result <- list(
    sd = sd(test_data_y - predicted_values),
    mean = mean(test_data_y - predicted_values),
    average_duration = (end_time - start_time) / times
  )

  result
}
```


# packages
## Rforestry
Supports both Random Forests and Gradient Boosting

```{r}
p_load(Rforestry)
```

Random Forest: uses `forestry` function

```{r}
benchmark(function() {
  forestry(x = training_data_x, y = training_data_y)
}, 10, "Benchmark with Rforestry forestry")
```

Gradient Boosting: uses `multiLayerForestry` function
```{r}
benchmark(function() {
  multilayerForestry(x = training_data_x, y = training_data_y)
}, 10, "Benchmark with Rforestry multilayerForestry")
```

## gbm
Gradient Boosting

```{r}

p_load(gbm)
```

Benchmark:
```{r}
benchmark(function() {
  gbm(formula,
    data = training_data
  )
}, 10, "Benchmark with gbm")
```
 
## caret
via https://www.r-bloggers.com/2018/11/machine-learning-basics-gradient-boosting-xgboost/

Predictions:
```{r}
benchmark(function() {
  caret::train(formula,
    data = training_data,
    method = "gbm",
    # preProcess = c("scale", "center"),
    verbose = 0
  )
}, 10, "Benchmark with caret")
```
